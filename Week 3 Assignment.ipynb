{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503980cf",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We load node and edge data from https://networkrepository.com/fb-pages-tvshow.php for mutually liked verified Facebook pages related to certain TV shows, originally collected in November 2017. Nodes represent TV show pages, and edges represent mutual likes among them. We eliminate pages with non-ASCII characters in their names, then take a small subset of the remaining pages for analysis and visualization. From this subset, we also eliminate any pages that are in isolation, i.e. those not connected to other pages by any mutual likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53144b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1006)\n",
    "fn_nodes = \"https://raw.githubusercontent.com/geedoubledee/data620_week3assignment/main/fb-pages-tvshow.nodes\"\n",
    "nodes_df = pd.read_csv(fn_nodes)\n",
    "subset = [\"name\", \"new_id\"]\n",
    "nodes_df = nodes_df[subset]\n",
    "def check_chars(s):\n",
    "    return s.isascii()\n",
    "nodes_df[\"chars_okay\"] = nodes_df[\"name\"].apply(check_chars)\n",
    "nodes_df = nodes_df[nodes_df[\"chars_okay\"] == True]\n",
    "nodes_df.sort_values(by=\"new_id\", inplace=True)\n",
    "nodes_dict = dict(zip(nodes_df.new_id, nodes_df.name))\n",
    "fn_edges = \"https://raw.githubusercontent.com/geedoubledee/data620_week3assignment/main/fb-pages-tvshow.edges\"\n",
    "resp = requests.get(fn_edges)\n",
    "G = nx.read_edgelist(io.BytesIO(resp.content), delimiter=\",\", nodetype=int)\n",
    "subset = random.sample(list(nodes_df[\"new_id\"]), 100)\n",
    "H = G.subgraph(subset)\n",
    "I = H.copy()\n",
    "I.remove_nodes_from(list(nx.isolates(H)))\n",
    "I = nx.relabel_nodes(I, nodes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89c678",
   "metadata": {},
   "source": [
    "Below is a visualization of the subset of connected TV pages we've selected. We will refer to this graph as subgraph I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5393c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
